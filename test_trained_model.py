import os
import time
import numpy as np
import torch
import cv2
import imageio
import clip
import ml_collections
import gymnasium as gym
import torchvision.transforms as T

from models import SACAgent, FuRLAgent, RewardModel
from utils import TASKS, get_logger, make_env, load_liv

# ğŸ”¹ í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
def get_test_config():
    config = ml_collections.ConfigDict()
    config.env_name = "peg-insert-side-v2-goal-observable"
    config.camera_id = 2
    config.seed = 0
    config.eval_episodes = 10  # í…ŒìŠ¤íŠ¸í•  ì—í”¼ì†Œë“œ ìˆ˜
    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œëŠ” ì ˆëŒ€ ê²½ë¡œë¡œ ì§€ì •
    config.ckpt_dir = os.path.abspath(f"save_models/{config.env_name}")
    return config

# ğŸ”¹ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
def load_trained_models(config):
    # LIV ëª¨ë¸ ë¡œë“œ
    transform = T.Compose([T.ToTensor()])
    liv = load_liv()

    # í™˜ê²½ ì´ˆê¸°í™”
    env = make_env(config.env_name, seed=config.seed, camera_id=config.camera_id)

    # CLIPì„ ì´ìš©í•œ ëª©í‘œ ì„ë² ë”© ë¡œë“œ
    with torch.no_grad():
        token = clip.tokenize([TASKS[config.env_name]])
        text_embedding = liv(input=token, modality="text")
    text_embedding = text_embedding.detach().cpu().numpy()

    # ëª¨ë¸ ì´ˆê¸°í™” ë° ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
    vlm_agent = FuRLAgent(obs_dim=env.observation_space.shape[0],
                          act_dim=env.action_space.shape[0],
                          max_action=env.action_space.high[0],
                          seed=config.seed,
                          ckpt_dir=config.ckpt_dir,
                          text_embedding=text_embedding,
                          goal_embedding=None)
    
    sac_agent = SACAgent(obs_dim=env.observation_space.shape[0],
                         act_dim=env.action_space.shape[0],
                         max_action=env.action_space.high[0],
                         seed=config.seed,
                         ckpt_dir=config.ckpt_dir)
    
    reward_model = RewardModel(seed=config.seed,
                               ckpt_dir=config.ckpt_dir,
                               text_embedding=text_embedding,
                               goal_embedding=None)

    # ë¶ˆëŸ¬ì˜¬ ì²´í¬í¬ì¸íŠ¸ ìŠ¤í… (ìµœê·¼ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°)
    vlm_ckpt_dir = os.path.join(config.ckpt_dir, "vlm_agent")
    # ì´ë¦„ì´ ìˆœìˆ˜ ìˆ«ìì¸ í´ë”ë§Œ í›„ë³´ë¡œ ì„ íƒ (ì„ì‹œ íŒŒì¼ ë“± ì œì™¸)
    ckpt_candidates = [d for d in os.listdir(vlm_ckpt_dir) if d.isdigit()]
    if not ckpt_candidates:
        raise ValueError(f"No valid checkpoint found in {vlm_ckpt_dir}")
    latest_ckpt = max([int(d) for d in ckpt_candidates])

    print(f"ğŸ”„ Loading checkpoint from step {latest_ckpt}")

    # config.ckpt_dirë§Œ ì „ë‹¬ (ë‚´ë¶€ì—ì„œ í•˜ìœ„ í´ë”ê°€ ì¶”ê°€ë¨)
    vlm_agent.load(config.ckpt_dir, latest_ckpt)
    sac_agent.load(config.ckpt_dir, latest_ckpt)
    reward_model.load(config.ckpt_dir, latest_ckpt)

    return env, vlm_agent, sac_agent, reward_model, transform, liv

# ğŸ”¹ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
def test_model():
    config = get_test_config()
    env, vlm_agent, sac_agent, reward_model, transform, liv = load_trained_models(config)
    
    eval_episodes = config.eval_episodes
    total_rewards = []
    success_count = 0
    video_frames = []

    print(f"ğŸš€ Running {eval_episodes} evaluation episodes...")

    for episode in range(eval_episodes):
        obs, _ = env.reset()
        episode_reward = 0
        done = False
        step_count = 0  # íƒ€ì„ìŠ¤í… ì¹´ìš´íŠ¸

        print(f"\nğŸ¬ Episode {episode + 1} start:")

        while not done:
            step_count += 1

            # VLM Agentì—ì„œ í–‰ë™ ìƒ˜í”Œë§
            action = vlm_agent.sample_action(obs, eval_mode=True)
            next_obs, env_reward, terminated, truncated, info = env.step(action)
            done = terminated or truncated

            # í™˜ê²½ì—ì„œ ë°›ì€ ë³´ìƒ (Task Reward)
            episode_reward += env_reward

            # ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ Reward ê³„ì‚°
            with torch.no_grad():
                image = env.mujoco_renderer.render(render_mode="rgb_array", camera_id=config.camera_id).copy()
                image = image[::-1]
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
                processed_image = transform(image)
                image_embedding = liv(input=processed_image.to("cuda")[None], modality="vision")
                image_embedding = image_embedding.detach().cpu().numpy()

                vlm_reward = reward_model.get_vlm_reward(reward_model.proj_state, image_embedding).item()

            # ë³´ìƒ ì¶œë ¥
            print(f"ğŸ”¹ Step {step_count} | Task Reward: {env_reward:.3f}, VLM Reward: {vlm_reward:.3f}")

            # ë¹„ë””ì˜¤ í”„ë ˆì„ ì €ì¥
            video_frames.append(image)

            obs = next_obs

        total_rewards.append(episode_reward)
        success_count += int(info["success"])
        print(f"âœ… Episode {episode + 1} completed. Total Reward: {episode_reward:.2f}, Success: {info['success']}")

    env.close()

    # í‰ê°€ ê²°ê³¼ ì¶œë ¥
    avg_reward = np.mean(total_rewards)
    success_rate = success_count / eval_episodes * 100
    print(f"\nğŸ“Š Average Reward: {avg_reward:.2f}")
    print(f"âœ… Success Rate: {success_rate:.2f}%")

    # ë¹„ë””ì˜¤ ì €ì¥
    video_path = os.path.join(config.ckpt_dir, "test_results.mp4")
    imageio.mimsave(video_path, video_frames, fps=30)
    print(f"ğŸ¥ Evaluation video saved at: {video_path}")

if __name__ == "__main__":
    test_model()
