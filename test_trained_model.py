import os
import time
import numpy as np
import torch
import cv2
import imageio
import clip
import ml_collections
import gymnasium as gym
import torchvision.transforms as T

from models import SACAgent, FuRLAgent, RewardModel
from utils import TASKS, get_logger, make_env, load_liv

# ğŸ”¹ í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
def get_test_config():
    config = ml_collections.ConfigDict()
    config.env_name = "door-open-v2-goal-hidden"
    config.camera_id = 2
    config.seed = 0
    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œëŠ” ì ˆëŒ€ ê²½ë¡œë¡œ ì§€ì •
    config.ckpt_dir = os.path.abspath(f"save_models/{config.env_name}")
    return config

# ğŸ”¹ í™˜ê²½, LIV, í…ìŠ¤íŠ¸ ì„ë² ë”©, ì „ì²˜ë¦¬ ë“± ì •ì  ì»´í¬ë„ŒíŠ¸ ë¡œë“œ í•¨ìˆ˜
def load_static_components(config):
    transform = T.Compose([T.ToTensor()])
    liv = load_liv()
    env = make_env(config.env_name, seed=config.seed, camera_id=config.camera_id)
    with torch.no_grad():
        token = clip.tokenize([TASKS[config.env_name]])
        text_embedding = liv(input=token, modality="text")
    text_embedding = text_embedding.detach().cpu().numpy()
    return env, transform, liv, text_embedding

# ğŸ”¹ 100000ë¶€í„° latest_ckptê¹Œì§€ 100000 ë‹¨ìœ„ ì²´í¬í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜
def get_checkpoint_list(config, start_ckpt=100000):
    vlm_ckpt_dir = os.path.join(config.ckpt_dir, "furl_agent")
    ckpt_candidates = [int(d) for d in os.listdir(vlm_ckpt_dir) if d.isdigit()]
    if not ckpt_candidates:
        raise ValueError(f"No valid checkpoint found in {vlm_ckpt_dir}")
    latest_ckpt = max(ckpt_candidates)
    # 100000 ë‹¨ìœ„ë¡œ ì²´í¬í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸ ìƒì„± (latest_ckptê°€ 100000ì˜ ë°°ìˆ˜ê°€ ì•„ë‹ˆì–´ë„, ê·¸ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì€ ê°’ë“¤)
    checkpoints = list(range(start_ckpt, latest_ckpt + 1, 100000))
    return checkpoints, latest_ckpt

# ğŸ”¹ ì£¼ì–´ì§„ ì²´í¬í¬ì¸íŠ¸ ë²ˆí˜¸ë¡œ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
def load_models_at_checkpoint(config, env, text_embedding, ckpt):
    vlm_agent = FuRLAgent(obs_dim=env.observation_space.shape[0],
                          act_dim=env.action_space.shape[0],
                          max_action=env.action_space.high[0],
                          seed=config.seed,
                          ckpt_dir=config.ckpt_dir,
                          text_embedding=text_embedding,
                          goal_embedding=None)
    
    sac_agent = SACAgent(obs_dim=env.observation_space.shape[0],
                         act_dim=env.action_space.shape[0],
                         max_action=env.action_space.high[0],
                         seed=config.seed,
                         ckpt_dir=config.ckpt_dir)
    
    reward_model = RewardModel(seed=config.seed,
                               ckpt_dir=config.ckpt_dir,
                               text_embedding=text_embedding,
                               goal_embedding=None)
    
    print(f"ğŸ”„ Loading checkpoint {ckpt}")
    vlm_agent.load(config.ckpt_dir, ckpt)
    sac_agent.load(config.ckpt_dir, ckpt)
    reward_model.load(config.ckpt_dir, ckpt)
    
    return vlm_agent, sac_agent, reward_model

# ğŸ”¹ ì²´í¬í¬ì¸íŠ¸ë³„ë¡œ í•œ ì—í”¼ì†Œë“œì”© í…ŒìŠ¤íŠ¸í•˜ê³  ì „ì²´ ì˜ìƒì„ ì €ì¥í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
def test_model():
    config = get_test_config()
    env, transform, liv, text_embedding = load_static_components(config)
    checkpoints, latest_ckpt = get_checkpoint_list(config)
    
    video_frames = []
    overall_rewards = {}
    overall_successes = {}
    
    print(f"ğŸš€ Testing checkpoints: {checkpoints}")
    
    # ê° ì²´í¬í¬ì¸íŠ¸ë§ˆë‹¤ í•œ ì—í”¼ì†Œë“œ ì‹¤í–‰
    for ckpt in checkpoints:
        episode_reward = 0
        step_count = 0
        
        # ê° ì²´í¬í¬ì¸íŠ¸ì— ëŒ€í•´ ëª¨ë¸ ë¡œë“œ
        vlm_agent, sac_agent, reward_model = load_models_at_checkpoint(config, env, text_embedding, ckpt)
        
        print(f"\nğŸ¬ Testing checkpoint {ckpt}:")
        obs, _ = env.reset()
        done = False
        
        while not done:
            step_count += 1
            # VLM Agentì—ì„œ í–‰ë™ ìƒ˜í”Œë§
            action = vlm_agent.sample_action(obs, eval_mode=True)
            next_obs, env_reward, terminated, truncated, info = env.step(action)
            done = terminated or truncated
            episode_reward += env_reward
            
            # ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ Reward ê³„ì‚°
            with torch.no_grad():
                image = env.mujoco_renderer.render(render_mode="rgb_array", camera_id=config.camera_id).copy()
                image = image[::-1]  # ì´ë¯¸ì§€ ìƒí•˜ ë°˜ì „
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
                processed_image = transform(image)
                image_embedding = liv(input=processed_image.to("cuda")[None], modality="vision")
                image_embedding = image_embedding.detach().cpu().numpy()
                
                vlm_reward = reward_model.get_vlm_reward(reward_model.proj_state, image_embedding).item()
            
            print(f"ğŸ”¹ Checkpoint {ckpt} | Step {step_count} | Task Reward: {env_reward:.3f}, VLM Reward: {vlm_reward:.3f}")
            
            # ë¹„ë””ì˜¤ í”„ë ˆì„ ì €ì¥ (ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ì˜ ì˜ìƒì´ í•˜ë‚˜ì˜ ë¹„ë””ì˜¤ì— ê¸°ë¡ë¨)
            video_frames.append(image)
            
            obs = next_obs
        
        overall_rewards[ckpt] = episode_reward
        overall_successes[ckpt] = info.get("success", False)
        print(f"âœ… Checkpoint {ckpt} episode completed. Total Reward: {episode_reward:.2f}, Success: {info.get('success', False)}")
    
    env.close()
    
    # ê° ì²´í¬í¬ì¸íŠ¸ì˜ í‰ê°€ ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š Evaluation Summary:")
    for ckpt in checkpoints:
        print(f"Checkpoint {ckpt} -> Total Reward: {overall_rewards[ckpt]:.2f}, Success: {overall_successes[ckpt]}")
    
    # ì „ì²´ ì˜ìƒ ì €ì¥ (ëª¨ë“  ì—í”¼ì†Œë“œì˜ í”„ë ˆì„ì„ í•˜ë‚˜ì˜ ì˜ìƒìœ¼ë¡œ ì €ì¥)
    video_path = os.path.join(config.ckpt_dir, "test_results.mp4")
    imageio.mimsave(video_path, video_frames, fps=30)
    print(f"\nğŸ¥ Evaluation video saved at: {video_path}")

if __name__ == "__main__":
    test_model()
